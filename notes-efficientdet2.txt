ML9 2080Ti

seed:		239
img_scale:	768
box_scale:	768
Build dataset:
   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
   5000/   5000	0010_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
    250/    250	0012_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   4940/   4940	0017_dataset_ysq1_1440_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
Training set:     57528
Test set:          3028
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  40


center offset: vehicle near image boundary

Catched exception
Traceback (most recent call last):
  File "train2.py", line 410, in train_one_epoch
    images = torch.stack(images)
TypeError: expected Tensor as element 2 in argument 0, but got numpy.ndarray
> /home/me/1TSSD/efficientdet-pytorch/train2.py(418)train_one_epoch()
-> images = images.to(self.device).float() / 255.0
(Pdb) type(images[0])
<class 'torch.Tensor'>
(Pdb) type(images[1])
<class 'torch.Tensor'>
(Pdb) type(images[2])
<class 'numpy.ndarray'>
(Pdb) images[0].shape
torch.Size([3, 768, 768])
(Pdb) images[1].shape
torch.Size([3, 768, 768])
(Pdb) images[2].shape
(768, 768, 3)
(Pdb) 

ToTensorV2(always_apply=True),

g = images[0].permute(1,2,0).cpu().numpy()
cv2.imshow("image", g)
cv2.waitKey()

class DatasetRetriever(Dataset):
    def __getitem__(self, index):
        if self.transform:
            for i in range(10):
                sample = self.transform(**{
                    'image': image,
                    'bboxes': target['boxes'],
                    'labels': labels,
                    'use_obb': True
                })
                sample = self.transform2(**{
                    'image': sample['image'],
                    'bboxes': sample['bboxes'],
                    'labels': sample['labels'],
                })
                image = sample['image']
                if len(sample['bboxes']) > 0:
                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)
                    #yxyx: be warning
                    #print(target['boxes'])
                    #print(target['boxes'].shape)
                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]
                    #print(target['boxes'].shape)
                    target['labels'] = torch.stack(sample['labels']) # <--- add this!
                    #print(target['boxes'].shape, target['labels'].shape)
                    #assert len(sample['bboxes']) == labels.shape[0], 'not equal!'
                    break
                else:
                    print(f"No VEHICLES for [{path}]!")
                    print(target)


No VEHICLES for [_models/075_reproduce_77_mAP_uint8_aug_web_collection_003_1184_10k_virtual_epoch_shiftscale_train0.95_seed239_retest/../../_datasets/0020_web-collection-003_1184_768_768_obb/timothy-tan-lhxQKdksvRw-unsplash_06.jpg]!
{'boxes': tensor([[668.7694,  27.3777, 733.4127,  56.6723, 280.0000]]), 'labels': tensor([1]), 'image_id': tensor([31005])}
{'image': tensor([[[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0]],

        [[0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         ...,
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0],
         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8), 'bboxes': tensor([[668.7694,  27.3777, 733.4127,  56.6723, 280.0000]]), 'labels': tensor([1]), 'use_obb': True}
<class 'torch.Tensor'>
Traceback (most recent call last):61.04756, time: 0.4 mins remaining: 13.0 mins            
  File "train2.py", line 704, in <module>
    run_training(net, output_path, logger)
  File "train2.py", line 568, in run_training
    fitter.fit(virtual_train_loader, val_loader)
  File "train2.py", line 339, in fit
    summary_loss = self.train_one_epoch(train_loader)
  File "train2.py", line 402, in train_one_epoch
    for step, (images, targets, image_ids) in enumerate(train_loader):
  File "train2.py", line 533, in __next__
    return next(self.iterator)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
    return self._process_data(data)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
    data.reraise()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
TypeError: Caught TypeError in DataLoader worker process 1.
Original Traceback (most recent call last):
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "train2.py", line 226, in __getitem__
    'use_obb': True
  File "/home/me/1TSSD/albumentations/albumentations/core/composition.py", line 166, in __call__
    self._check_args(**data)
  File "/home/me/1TSSD/albumentations/albumentations/core/composition.py", line 223, in _check_args
    raise TypeError("{} must be numpy array type".format(data_name))
TypeError: image must be numpy array type


No VEHICLES for [_models/075_reproduce_77_mAP_uint8_aug_web_collection_003_1184_10k_virtual_epoch_shiftscale_train0.95_seed239_retest/../../_datasets/0020_web-collection-003_1184_768_768_obb/vjshi.com_2020-09-09_c57176174ffb24a2189cd5e958e90cac_00004_09.jpg]!
{'boxes': tensor([[722.8071, 743.6644, 768.0000, 768.0000, 270.0000]]), 'labels': tensor([1]), 'image_id': tensor([21827])}
Traceback (most recent call last):: 0.16598, time: 5.6 mins remaining: 7.5 mins            
  File "train2.py", line 705, in <module>
    run_training(net, output_path, logger)
  File "train2.py", line 569, in run_training
    fitter.fit(virtual_train_loader, val_loader)
  File "train2.py", line 340, in fit
    summary_loss = self.train_one_epoch(train_loader)
  File "train2.py", line 435, in train_one_epoch
    outputs = self.model(images, target_res)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/bench.py", line 94, in forward
    x.shape[0], target['bbox'], target['cls'])
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/anchors.py", line 411, in batch_label_anchors
    anchor_box_list, BoxList(gt_boxes[i]), gt_classes[i])
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/object_detection/target_assigner.py", line 144, in assign
    match_quality_matrix = self._similarity_calc.compare(groundtruth_boxes, anchors)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/object_detection/region_similarity_calculator.py", line 101, in compare
    return iou(boxlist1, boxlist2)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/object_detection/region_similarity_calculator.py", line 69, in iou
    intersections = intersection(boxlist1, boxlist2)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/object_detection/region_similarity_calculator.py", line 48, in intersection
    y_min1, x_min1, y_max1, x_max1 = boxlist1.boxes().chunk(4, dim=1)
ValueError: not enough values to unpack (expected 4, got 3)

Found non-tensor inputs!
[torch.Size([3, 768, 768]), torch.Size([3, 768, 768]), torch.Size([3, 768, 768]), (768, 768, 3)]
>>> a=np.array([[[1,1],[2,2],[3,2]],[[2,3],[3,3],[4,4]],[[2,3],[3,3],[4,4]]])
>>> ToTensorV2()(image=a)['image'].shape
torch.Size([2, 3, 3])
>>> a.shape
(3, 3, 2)
>>> isinstance(ToTensorV2()(image=a)['image'], torch.Tensor)
True
  reuse last sample if there's no box for augmented image for 10 loops...



Try train with different resolution
Traceback (most recent call last):.00000, time: 0.0 mins remaining: 8.1 mins            
  File "train2.py", line 713, in <module>
    run_training(net, output_path, logger)
  File "train2.py", line 576, in run_training
    fitter.fit(virtual_train_loader, val_loader)
  File "train2.py", line 344, in fit
    summary_loss = self.train_one_epoch(train_loader)
  File "train2.py", line 418, in train_one_epoch
    images = torch.stack(images)
RuntimeError: stack expects each tensor to be equal size, but got [3, 768, 768] at entry 0 and [3, 1024, 1024] at entry 1
  cannot stack sample with different resolution in the same batch...

Traceback (most recent call last):.00000, time: 0.0 mins remaining: 11.6 mins            
  File "train2.py", line 713, in <module>
    run_training(net, output_path, logger)
  File "train2.py", line 576, in run_training
    fitter.fit(virtual_train_loader, val_loader)
  File "train2.py", line 344, in fit
    summary_loss = self.train_one_epoch(train_loader)
  File "train2.py", line 442, in train_one_epoch
    outputs = self.model(images, target_res)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/bench.py", line 95, in forward
    loss, class_loss, box_loss = self.loss_fn(class_out, box_out, cls_targets, box_targets, num_positives)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/loss.py", line 181, in forward
    alpha=self.alpha, gamma=self.gamma)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/loss.py", line 106, in _classification_loss
    classification_loss = focal_loss(cls_outputs, cls_targets, alpha, gamma, normalizer)
  File "/home/me/1TSSD/efficientdet-pytorch/effdet/loss.py", line 31, in focal_loss
    cross_entropy = F.binary_cross_entropy_with_logits(logits, targets.to(logits.dtype), reduction='none')
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/nn/functional.py", line 2538, in binary_cross_entropy_with_logits
    raise ValueError("Target size ({}) must be the same as input size ({})".format(target.size(), input.size()))
ValueError: Target size (torch.Size([2, 96, 96, 9])) must be the same as input size (torch.Size([2, 128, 128, 9]))
  shape error on forcus loss computation...

but inferencing is resolution-independent? why not for train even with batch_size==1


seed:		167
img_scale:	768
box_scale:	768
Build dataset:
   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
   5000/   5000	0010_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
    250/    250	0012_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   4940/   4940	0017_dataset_ysq1_1440_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
   1896/   1896	0022_UAV-ROD_dataset
   8236/   8236	0023_VSAI_dataset
Training set:     67153
Test set:          3535
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  40



--+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:86.69
Traceback (most recent call last): 0.19080, time: 4.0 mins remaining: 8.9 mins             
  File "train2.py", line 716, in <module>
    run_training(net, output_path, logger)
  File "train2.py", line 576, in run_training
    fitter.fit(virtual_train_loader, val_loader)
  File "train2.py", line 344, in fit
    summary_loss = self.train_one_epoch(train_loader)
  File "train2.py", line 407, in train_one_epoch
    for step, (images, targets, image_ids, image_paths) in enumerate(train_loader):
  File "train2.py", line 541, in __next__
    return next(self.iterator)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
    return self._process_data(data)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
    data.reraise()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
ValueError: Caught ValueError in DataLoader worker process 3.
Original Traceback (most recent call last):
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "train2.py", line 229, in __getitem__
    'use_obb': True
  File "/home/me/1TSSD/albumentations/albumentations/core/composition.py", line 180, in __call__
    p.preprocess(data)
  File "/home/me/1TSSD/albumentations/albumentations/core/utils.py", line 62, in preprocess
    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction="to")
  File "/home/me/1TSSD/albumentations/albumentations/core/utils.py", line 70, in check_and_convert
    return self.convert_to_albumentations(data, rows, cols)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 51, in convert_to_albumentations
    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 303, in convert_bboxes_to_albumentations
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 303, in <listcomp>
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 251, in convert_bbox_to_albumentations
    check_bbox(bbox)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 334, in check_bbox
    raise ValueError("x_max is less than or equal to x_min for bbox {bbox}.".format(bbox=bbox))
ValueError: x_max is less than or equal to x_min for bbox (tensor(0.3089), tensor(0.8643), tensor(0.3089), tensor(0.8643), tensor(0.), tensor(1)).

MMARY:88.27
./train99_ablation.sh: line 253: 7: command not found
seed:		167
img_scale:	768
box_scale:	768
Build dataset:
   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
   5000/   5000	0010_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
    250/    250	0012_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   4940/   4940	0017_dataset_ysq1_1440_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
   1896/   1896	0022_UAV-ROD_dataset
   8236/   8236	0023_VSAI_dataset
   9708/   9708	0025_DroneVehicle_dataset
Training set:     76376
Test set:          4020
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  40
<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
Fitter prepared. Device is cuda:0

2022-09-15T20:02:23.853196
LR: 0.0001
Traceback (most recent call last):.00000, time: 0.0 mins remaining: 10.0 mins            
  File "train2.py", line 723, in <module>
    run_training(net, output_path, logger)
  File "train2.py", line 583, in run_training
    fitter.fit(virtual_train_loader, val_loader)
  File "train2.py", line 344, in fit
    summary_loss = self.train_one_epoch(train_loader)
  File "train2.py", line 445, in train_one_epoch
    loss.backward()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 1.57 GiB (GPU 0; 10.76 GiB total capacity; 7.73 GiB already allocated; 1.57 GiB free; 7.77 GiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f3efb1251e2 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f3efb37b64b in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f3efb37c464 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5e (0x7f3efb3758de in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0xec0586 (0x7f3efc44e586 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xec506c (0x7f3efc45306c in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xebda3a (0x7f3efc44ba3a in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xebe24e (0x7f3efc44c24e in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #8: <unknown function> + 0xebe910 (0x7f3efc44c910 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #9: at::native::cudnn_convolution_backward_weight(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0x49 (0x7f3efc44cb69 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xf1f53b (0x7f3efc4ad53b in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #11: <unknown function> + 0xf4f178 (0x7f3efc4dd178 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #12: at::cudnn_convolution_backward_weight(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0x1ad (0x7f3f373852ad in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x18a (0x7f3efc44678a in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0xf1f445 (0x7f3efc4ad445 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #15: <unknown function> + 0xf4f1d4 (0x7f3efc4dd1d4 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #16: at::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x1e2 (0x7f3f37394242 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2ec9c62 (0x7f3f39057c62 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x2ede224 (0x7f3f3906c224 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #19: at::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x1e2 (0x7f3f37394242 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x258 (0x7f3f38edec38 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x3375bb7 (0x7f3f39503bb7 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #22: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f3f394ff400 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #23: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f3f394fffa1 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #24: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f3f394f8119 in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #25: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f3f46c98dea in /home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/lib/libtorch_python.so)
frame #26: <unknown function> + 0xc819d (0x7f3f592a419d in /home/me/anaconda3/envs/efficientdet-pytorch/bin/../lib/libstdc++.so.6)
frame #27: <unknown function> + 0x76db (0x7f3f622bf6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #28: clone + 0x3f (0x7f3f61fe861f in /lib/x86_64-linux-gnu/libc.so.6)

(efficientdet-pytorch) me@ML9:~/1TSSD/efficientdet-pytorch$ 
(efficientdet-pytorch) me@ML9:~/1TSSD/efficientdet-pytorch$ 


2022-09-16T02:06:36.708330
LR: 0.0001
[RESULT]: Train. Epoch: 0, summary_loss: 7.73538, time: 12.8 mins                           
Traceback (most recent call last):.39619, time: 1.2 mins remaining: 0.3 mins           
  File "train2.py", line 723, in <module>
    run_training(net, output_path, logger)
  File "train2.py", line 583, in run_training
    fitter.fit(virtual_train_loader, val_loader)
  File "train2.py", line 350, in fit
    summary_loss = self.validation(validation_loader)
  File "train2.py", line 374, in validation
    for step, (images, targets, image_ids, image_paths) in enumerate(val_loader):
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
    return self._process_data(data)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
    data.reraise()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
ValueError: Caught ValueError in DataLoader worker process 2.
Original Traceback (most recent call last):
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "train2.py", line 229, in __getitem__
    'use_obb': True
  File "/home/me/1TSSD/albumentations/albumentations/core/composition.py", line 180, in __call__
    p.preprocess(data)
  File "/home/me/1TSSD/albumentations/albumentations/core/utils.py", line 62, in preprocess
    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction="to")
  File "/home/me/1TSSD/albumentations/albumentations/core/utils.py", line 70, in check_and_convert
    return self.convert_to_albumentations(data, rows, cols)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 51, in convert_to_albumentations
    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 303, in convert_bboxes_to_albumentations
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 303, in <listcomp>
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 251, in convert_bbox_to_albumentations
    check_bbox(bbox)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 334, in check_bbox
    raise ValueError("x_max is less than or equal to x_min for bbox {bbox}.".format(bbox=bbox))
ValueError: x_max is less than or equal to x_min for bbox (tensor(0.3089), tensor(0.8643), tensor(0.3089), tensor(0.8643), tensor(0.), tensor(1)).





2022-09-16T06:57:40.254054
LR: 0.0001
/home/me/1TSSD/efficientdet-pytorch/_models/081_UAV-ROD_VSAI_DroneVehicle_train0.95_seed167/best-checkpoint-012epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.52% | 99.52% | 99.52% | 99.48% | 99.32% | 99.06% | 98.42% | 93.49% | 69.05% |  7.64% | 86.50% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:86.50
[RESULT]: Train. Epoch: 13, summary_loss: 0.17228, time: 12.8 mins                          
Traceback (most recent call last):.16783, time: 1.1 mins remaining: 0.3 mins           
  File "train2.py", line 566, in __next__
    return next(self.iterator)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
    return self._process_data(data)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
    data.reraise()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
ValueError: Caught ValueError in DataLoader worker process 2.
Original Traceback (most recent call last):
  File "train2.py", line 566, in __next__
    return next(self.iterator)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 964, in _next_data
    raise StopIteration
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/me/anaconda3/envs/efficientdet-pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "train2.py", line 229, in __getitem__
    'use_obb': True
  File "/home/me/1TSSD/albumentations/albumentations/core/composition.py", line 180, in __call__
    p.preprocess(data)
  File "/home/me/1TSSD/albumentations/albumentations/core/utils.py", line 62, in preprocess
    data[data_name] = self.check_and_convert(data[data_name], rows, cols, direction="to")
  File "/home/me/1TSSD/albumentations/albumentations/core/utils.py", line 70, in check_and_convert
    return self.convert_to_albumentations(data, rows, cols)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 51, in convert_to_albumentations
    return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity=True)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 303, in convert_bboxes_to_albumentations
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 303, in <listcomp>
    return [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) for bbox in bboxes]
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 251, in convert_bbox_to_albumentations
    check_bbox(bbox)
  File "/home/me/1TSSD/albumentations/albumentations/augmentations/bbox_utils.py", line 334, in check_bbox
    raise ValueError("x_max is less than or equal to x_min for bbox {bbox}.".format(bbox=bbox))
ValueError: x_max is less than or equal to x_min for bbox (tensor(0.3089), tensor(0.8643), tensor(0.3089), tensor(0.8643), tensor(0.), tensor(1)).

[RESULT]: Val. Epoch: 13, summary_loss: 0.16761, time: 1.4 mins                         


----------------------------------------------------------------------------------

# rebuild DroneVehicle and workaround invalid samples in data_loader
# cp train81.py train2.py
# python train2.py 081_UAV-ROD_VSAI_DroneVehicle_train0.95_seed167 167

seed:		167
img_scale:	768
box_scale:	768
Build dataset:
   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
   5000/   5000	0010_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
    250/    250	0012_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   4940/   4940	0017_dataset_ysq1_1440_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
   1896/   1896	0022_UAV-ROD_dataset
   8236/   8236	0023_VSAI_dataset
   9708/   9708	0025_DroneVehicle_dataset
Training set:     76376
Test set:          4020
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  40
<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>

/home/me/1TSSD/efficientdet-pytorch/_models/081_UAV-ROD_VSAI_DroneVehicle_train0.95_seed167/best-checkpoint-036epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.41% | 99.41% | 99.41% | 99.41% | 99.30% | 99.09% | 98.72% | 96.56% | 80.17% | 13.64% | 88.51% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
88.16_0.23

----------------------------------------------------------------------------------

# more test on exception handing in data_loader
# clean up new datasets with too much black area
# remove small vehicles  from 1536_768 datasets
# Add AABB dataset VAID
#cp train83.py train2.py
#python train2.py 083_UAV-ROD_VSAI_DroneVehicle_VAID_aabb_train0.95_seed167 167

seed:		167
img_scale:	768
box_scale:	768
Build dataset:
   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
   1604/   1604	0022_UAV-ROD_dataset
   7343/   7343	0023_VSAI_dataset
   9708/   9708	0024_DroneVehicle_dataset
  10420/  10420	0025_VAID_dataset_aabb
Training set:     75468
Test set:          3973
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  40
<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>


/home/me/1TSSD/efficientdet-pytorch/_models/083_UAV-ROD_VSAI_DroneVehicle_VAID_aabb_train0.95_seed167/best-checkpoint-038epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.56% | 99.56% | 99.56% | 99.56% | 99.45% | 99.14% | 98.71% | 95.53% | 75.08% | 10.53% | 87.67% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
87.22_0.31
	081 vs 083
		remove 1536 images and adding VAID_aabb
			make mAP_95_50 worse and more noisy
			with similar lr steps
----------------------------------------------------------------------------------
# train82 with AABB dataset VAID, VEDAI and 1536_768 datasets
# min_lr=lr/16, patient=5, max_epoch=80
#cp train84.py train2.py
#python train2.py 084_UAV-ROD_VSAI_DroneVehicle_train0.95_seed167 167
  too patient...
    reduce to 1/2 @ 40th epoch
    reduce to 1/4 @ 80th epoch
    best mAP @ 80th epoch

seed:		167
img_scale:	768
box_scale:	768
Build dataset:
   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
   5000/   5000	0010_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
    250/    250	0012_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   4940/   4940	0017_dataset_ysq1_1440_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
   1604/   1604	0022_UAV-ROD_dataset
   7343/   7343	0023_VSAI_dataset
   9708/   9708	0024_DroneVehicle_dataset
  10420/  10420	0025_VAID_dataset_aabb
   1923/   1923	0026_VEDAI_dataset
Training set:     86976
Test set:          4578
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  80
<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>

/home/me/1TSSD/efficientdet-pytorch/_models/084_UAV-ROD_VSAI_DroneVehicle_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.45% | 99.45% | 99.45% | 99.42% | 99.34% | 99.20% | 98.62% | 96.47% | 79.04% | 14.69% | 88.52% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
87.54_0.58
	it doesn't help to just be much more patient in training...
----------------------------------------------------------------------------------
# train82 with AABB dataset VAID, VEDAI and 1536_768 datasets
# min_lr=lr/16, patient=2, max_epoch=80
cp train85.py train2.py
python train2.py 085_UAV-ROD_VSAI_DroneVehicle_train0.95_seed167 167

Training set:     86976
Test set:          4578
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  80

2022-09-19T13:42:02.305687
LR: 6.25e-06
/home/me/1TSSD/efficientdet-pytorch/_models/085_UAV-ROD_VSAI_DroneVehicle_train0.95_seed167/best-checkpoint-066epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.50% | 99.50% | 99.50% | 99.50% | 99.39% | 99.18% | 98.59% | 96.32% | 76.82% | 11.12% | 87.94% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:87.94
[RESULT]: Train. Epoch: 67, summary_loss: 0.13900, time: 15.7 mins                          
[RESULT]: Val. Epoch: 67, summary_loss: 0.14031, time: 3.3 mins     
  at least one dataset is too different from the original 2021 dataset
    VSAI
      need to filter out images with unrelated view angles
87.68_0.12
	lr reduced to fast. 16 30 36 44
----------------------------------------------------------------------------------
# train82 without 5 new datasets
# min_lr=lr/16, patient=2, max_epoch=80
cp train86.py train2.py
python train2.py 086_patient2_80epochs_train0.95_seed167 167

[RESULT]: Train. Epoch: 51, summary_loss: 0.09327, time: 16.0 mins                          
[RESULT]: Val. Epoch: 51, summary_loss: 0.09267, time: 2.3 mins                       
2022-09-20T09:48:43.597647
LR: 1.25e-05
/home/me/1TSSD/efficientdet-pytorch/_models/086_UAV-ROD_VSAI_DroneVehicle_patient2_80epochs_train0.95_seed167/best-checkpoint-051epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.39% | 99.39% | 99.39% | 99.39% | 99.28% | 98.96% | 98.66% | 96.63% | 80.16% | 17.04% | 88.83% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.83
88.46_0.10
	lr steps are fine: 34 40 50 64
----------------------------------------------------------------------------------
# train82 only add 0023_VSAI_dataset_2(filtered)
# min_lr=lr/16, patient=2, max_epoch=80
cp train91.py train2.py
python train2.py 091_VSAI_patient2_80epochs_train0.95_seed167 167

[RESULT]: Train. Epoch: 48, summary_loss: 0.10601, time: 16.0 mins                          
[RESULT]: Val. Epoch: 48, summary_loss: 0.10469, time: 2.3 mins                       
2022-09-21T09:30:47.153401
LR: 0.0001
/home/me/1TSSD/efficientdet-pytorch/_models/091_VSAI_patient2_80epochs_train0.95_seed167/best-checkpoint-048epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.52% | 99.48% | 99.48% | 99.38% | 99.28% | 98.92% | 98.60% | 96.92% | 82.70% | 16.19% | 89.05% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:89.05

[RESULT]: Train. Epoch: 69, summary_loss: 0.08818, time: 16.0 mins                          
[RESULT]: Val. Epoch: 69, summary_loss: 0.08699, time: 2.3 mins                       
2022-09-21T15:54:39.179915
LR: 2.5e-05
/home/me/1TSSD/efficientdet-pytorch/_models/091_VSAI_patient2_80epochs_train0.95_seed167/best-checkpoint-069epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.49% | 99.45% | 99.45% | 99.45% | 99.34% | 99.09% | 98.48% | 96.64% | 80.71% | 17.13% | 88.92% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.92
88.53_0.15
	lr steps are more patient than 086: 55 65 74 @@@@@@@
	not converged yet.
		it suggests to use high lr or training longer in high lr.
----------------------------------------------------------------------------------
# train94 with 4 more dataset except DroneVehicle
# min_lr=lr/16, patient=2, max_epoch=80
cp train94.py train2.py
python train2.py 094_UAV-ROD_VSAI_VAID_VEDAI_patient2_80epochs_train0.95_seed167 167

[RESULT]: Train. Epoch: 13, summary_loss: 0.14683, time: 15.7 mins                          
[RESULT]: Val. Epoch: 13, summary_loss: 0.14343, time: 2.7 mins                       
2022-09-21T23:25:50.463415
LR: 0.0001
/home/me/1TSSD/efficientdet-pytorch/_models/094_UAV-ROD_VSAI_VAID_VEDAI_patient2_80epochs_train0.95_seed167/best-checkpoint-013epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.44% | 99.44% | 99.41% | 99.37% | 99.24% | 99.05% | 98.29% | 94.12% | 72.03% |  9.96% | 87.04% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:87.04

2022-09-22T19:24:26.241130
LR: 6.25e-06
[RESULT]: Train. Epoch: 79, summary_loss: 0.10039, time: 15.8 mins                  
[RESULT]: Val. Epoch: 79, summary_loss: 0.10342, time: 2.7 mins
/home/me/1TSSD/efficientdet-pytorch/_models/094_UAV-ROD_VSAI_VAID_VEDAI_patient2_80epochs_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.51% | 99.51% | 99.51% | 99.48% | 99.40% | 99.11% | 98.70% | 97.11% | 80.83% | 15.31% | 88.85% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.85
  become a little bit hard to get high 88.xx% mAP and need to train longer
    new labels are more noisy, I guess...
88.41_0.17
	lr reduced faster than 091, but got similar result
		train longer I guess
----------------------------------------------------------------------------------
# train94 only with 5 new dataset
# min_lr=lr/16, patient=1, max_epoch=40
cp trainz0000.py train2.py
python train2.py z0000_UAV-ROD_VSAI_VAID_VEDAI_DroneVehicle_train0.95_seed167 167
  any surprise?

   1604/   1604	0022_UAV-ROD_dataset
    688/    688	0023_VSAI_dataset_2
   9708/   9708	0024_DroneVehicle_dataset
  10420/  10420	0025_VAID_dataset_aabb
   1923/   1923	0026_VEDAI_dataset

[RESULT]: Train. Epoch: 14, summary_loss: 0.19605, time: 12.7 mins                          
[RESULT]: Val. Epoch: 14, summary_loss: 0.19212, time: 0.4 mins                       
2022-09-23T05:59:47.464636
LR: 5e-05
/home/me/1TSSD/efficientdet-pytorch/_models/z0000_UAV-ROD_VSAI_VAID_VEDAI_DroneVehicle_train0.95_seed167/best-checkpoint-014epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 98.95% | 98.95% | 98.89% | 98.81% | 98.63% | 98.38% | 97.37% | 92.12% | 62.62% |  5.37% | 85.01% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:85.01

2022-09-23T11:14:57.290488
LR: 6.25e-06
[RESULT]: Train. Epoch: 39, summary_loss: 0.17253, time: 12.6 mins                  
[RESULT]: Val. Epoch: 39, summary_loss: 0.17402, time: 0.4 mins                   
/home/me/1TSSD/efficientdet-pytorch/_models/z0000_UAV-ROD_VSAI_VAID_VEDAI_DroneVehicle_train0.95_seed167/best-checkpoint-039epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 98.96% | 98.96% | 98.92% | 98.82% | 98.68% | 98.34% | 96.81% | 86.99% | 45.80% |  4.29% | 82.66% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:82.66
	no overfitting yet
82.80_0.68
	The 5 new datasets are not good as my 2021 dataset.
		086 vs z0000
			~5.7% mAP95_50 gap
----------------------------------------------------------------------------------
# train94 only with only DroneVehicle
# min_lr=lr/16, patient=1, max_epoch=40
cp trainz0001.py train2.py
python train2.py z0001_DroneVehicle_only_train0.95_seed167 167

9708/   9708	0024_DroneVehicle_dataset

[RESULT]: Train. Epoch: 34, summary_loss: 0.16753, time: 13.0 mins                          
[RESULT]: Val. Epoch: 34, summary_loss: 0.18123, time: 0.2 mins                       
2022-09-27T01:02:58.736708
LR: 6.25e-06
/home/me/1TSSD/efficientdet-pytorch/_models/z0001_DroneVehicle_only_train0.95_seed167/best-checkpoint-034epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 98.97% | 98.93% | 98.93% | 98.93% | 98.76% | 98.41% | 97.53% | 93.12% | 66.32% |  9.15% | 85.91% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:85.91

[RESULT]: Train. Epoch: 39, summary_loss: 0.16646, time: 13.0 mins                          
[RESULT]: Val. Epoch: 39, summary_loss: 0.17886, time: 0.2 mins                       
/home/me/1TSSD/efficientdet-pytorch/_models/z0001_DroneVehicle_only_train0.95_seed167/best-checkpoint-039epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.01% | 98.97% | 98.94% | 98.94% | 98.70% | 98.43% | 97.25% | 89.49% | 58.43% |  6.63% | 84.48% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:84.48
	only a little overfitting
85.26_0.30
	start overfitting @ 21th epoch
----------------------------------------------------------------------------------
# train94 only with only VAID_aabb
# min_lr=lr/16, patient=1, max_epoch=40
cp trainz0002.py train2.py
python train2.py z0002_VAID_aabb_only_train0.95_seed167 167

10420/  10420	0025_VAID_dataset_aabb

[RESULT]: Train. Epoch: 14, summary_loss: 0.15962, time: 12.8 mins                          
[RESULT]: Val. Epoch: 14, summary_loss: 0.18285, time: 0.2 mins                       
2022-09-27T05:33:45.515981
LR: 5e-05
/home/me/1TSSD/efficientdet-pytorch/_models/z0002_VAID_aabb_only_train0.95_seed167/best-checkpoint-014epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 97.99% | 97.91% | 97.81% | 97.68% | 96.97% | 93.44% | 75.41% | 45.86% | 15.54% |  0.69% | 71.93% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:71.93

[RESULT]: Train. Epoch: 39, summary_loss: 0.13491, time: 12.6 mins                          
[RESULT]: Val. Epoch: 39, summary_loss: 0.17131, time: 0.2 mins                       
/home/me/1TSSD/efficientdet-pytorch/_models/z0002_VAID_aabb_only_train0.95_seed167/best-checkpoint-039epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 97.33% | 97.26% | 97.06% | 96.84% | 96.00% | 90.54% | 68.45% | 35.02% | 10.07% |  0.43% | 68.90% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:68.90
	a bit overfitting (due to no rotation aug)
69.06_0.25
	start overfitting @ 8th epoch
----------------------------------------------------------------------------------
# train94 only with only VSAI
# min_lr=lr/16, patient=1, max_epoch=40
cp trainz0003.py train2.py
python train2.py z0003_VSAI_only_train0.95_seed167 167

688/    688	0023_VSAI_dataset_2

[RESULT]: Train. Epoch: 2, summary_loss: 0.21106, time: 12.7 mins                           
[RESULT]: Val. Epoch: 2, summary_loss: 0.19984, time: 0.0 mins                    
2022-09-27T11:44:50.053714
LR: 0.0001
/home/me/1TSSD/efficientdet-pytorch/_models/z0003_VSAI_only_train0.95_seed167/best-checkpoint-002epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 98.59% | 98.59% | 98.44% | 98.34% | 98.16% | 97.62% | 94.73% | 77.82% | 37.37% |  2.49% | 80.21% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:80.21

[RESULT]: Train. Epoch: 23, summary_loss: 0.08144, time: 12.7 mins                          
[RESULT]: Val. Epoch: 23, summary_loss: 0.16867, time: 0.0 mins                   
2022-09-27T16:11:32.713691
LR: 6.25e-06
/home/me/1TSSD/efficientdet-pytorch/_models/z0003_VSAI_only_train0.95_seed167/best-checkpoint-023epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 98.36% | 98.29% | 98.14% | 97.99% | 97.88% | 96.82% | 91.06% | 62.93% | 17.00% |  0.30% | 75.88% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:75.88
	heavily overfitting
76.14_0.71
	start overfitting @ 8th epoch
----------------------------------------------------------------------------------
# train94 only with only UAV-ROD
# min_lr=lr/16, patient=1, max_epoch=40
cp trainz0004.py train2.py
python train2.py z0004_UAV-ROD_only_train0.95_seed167 167

1604/   1604	0022_UAV-ROD_dataset


[RESULT]: Train. Epoch: 14, summary_loss: 0.05574, time: 12.8 mins                          
[RESULT]: Val. Epoch: 14, summary_loss: 0.06271, time: 0.0 mins                     
2022-09-27T19:28:24.261726
LR: 5e-05
/home/me/1TSSD/efficientdet-pytorch/_models/z0004_UAV-ROD_only_train0.95_seed167/best-checkpoint-014epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 94.57% | 94.37% | 94.20% | 93.82% | 93.37% | 92.78% | 90.38% | 76.29% | 31.12% |  0.86% | 76.18% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:76.18

[RESULT]: Train. Epoch: 39, summary_loss: 0.03880, time: 12.8 mins                          
[RESULT]: Val. Epoch: 39, summary_loss: 0.04984, time: 0.0 mins                     
/home/me/1TSSD/efficientdet-pytorch/_models/z0004_UAV-ROD_only_train0.95_seed167/best-checkpoint-039epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 95.28% | 95.25% | 95.18% | 94.90% | 94.21% | 92.86% | 87.12% | 58.99% | 11.51% |  0.08% | 72.54% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:72.54
	overfitting @ 40th epoch
	start overfitting @ 21th epoch
72.56_0.16
----------------------------------------------------------------------------------
# train94 only with only VEDAI
# min_lr=lr/16, patient=1, max_epoch=40
cp trainz0005.py train2.py
python train2.py z0005_VEDAI_only_train0.95_seed167 167

1923/   1923	0026_VEDAI_dataset

[RESULT]: Train. Epoch: 4, summary_loss: 0.32237, time: 12.8 mins                           
[RESULT]: Val. Epoch: 4, summary_loss: 0.39606, time: 0.0 mins                      
2022-09-28T02:03:42.975288
LR: 0.0001
/home/me/1TSSD/efficientdet-pytorch/_models/z0005_VEDAI_only_train0.95_seed167/best-checkpoint-004epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 96.55% | 96.44% | 96.40% | 96.17% | 95.28% | 94.48% | 90.78% | 76.77% | 35.53% |  1.65% | 78.01% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:78.01

[RESULT]: Train. Epoch: 39, summary_loss: 0.19090, time: 12.8 mins                          
[RESULT]: Val. Epoch: 39, summary_loss: 0.42247, time: 0.0 mins                     
/home/me/1TSSD/efficientdet-pytorch/_models/z0005_VEDAI_only_train0.95_seed167/best-checkpoint-039epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 93.31% | 93.24% | 93.02% | 92.40% | 90.92% | 87.48% | 77.42% | 54.27% | 18.08% |  0.48% | 70.06% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:70.06
	heavily overfitting @ 40th epoch
	start overfitting @ 5th epoch
69.40_0.69
----------------------------------------------------------------------------------

# train94 only with 4 new datasets except VAID_aabb
# min_lr=lr/16, patient=2, max_epoch=80
cp trainz0006.py train2.py
python train2.py z0006_except_VAID_aabb_patient2_80epochs_train0.95_seed167 167

   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
   5000/   5000	0010_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
    250/    250	0012_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   4940/   4940	0017_dataset_ysq1_1440_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
   1604/   1604	0022_UAV-ROD_dataset
    688/    688	0023_VSAI_dataset_2
   9708/   9708	0024_DroneVehicle_dataset
   1923/   1923	0026_VEDAI_dataset
Training set:     70755
Test set:          3724
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  80

[RESULT]: Train. Epoch: 54, summary_loss: 0.11247, time: 12.8 mins                          
[RESULT]: Val. Epoch: 54, summary_loss: 0.11431, time: 1.3 mins                       
2022-09-29T03:26:04.772332
LR: 1.25e-05
/home/me/1TSSD/efficientdet-pytorch/_models/z0006_except_VAID_aabb_patient2_80epochs_train0.95_seed167/best-checkpoint-054epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.48% | 99.48% | 99.48% | 99.48% | 99.40% | 99.26% | 98.90% | 96.84% | 79.58% | 15.01% | 88.69% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.69

[RESULT]: Train. Epoch: 79, summary_loss: 0.10784, time: 12.8 mins                          
[RESULT]: Val. Epoch: 79, summary_loss: 0.11005, time: 1.3 mins                       
/home/me/1TSSD/efficientdet-pytorch/_models/z0006_except_VAID_aabb_patient2_80epochs_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.45% | 99.45% | 99.45% | 99.45% | 99.37% | 99.22% | 98.96% | 96.78% | 76.61% | 12.38% | 88.11% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.11
88.25_0.10
----------------------------------------------------------------------------------
# train94 only with 5 new datasets including VAID_aabb
# min_lr=lr/16, patient=2, max_epoch=80
cp trainz0008.py train2.py
python train2.py z0008_only_5_new_dataset_including_VAID_aabb_patient2_80epochs_train0.95_seed167 167

   5000/   5000	0009_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb
   5000/   5000	0010_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb
    250/    250	0011_dataset_20200901M2_20200907_1202_200m_fixed_768_768_obb_bus
    250/    250	0012_dataset_20200901M2_20200907_1202_200m_fixed_1536_768_obb_bus
   3124/   3124	0013_dataset_tongji_011_768_768_obb
   5000/   5000	0014_dataset_20200901M2_20200903_1205_250m_fixed_768_768_obb
   5000/   5000	0015_dataset_20200901M2_20200907_1104_200m_fixed_768_768_obb
   4940/   4940	0016_dataset_ysq1_768_768_obb
   4940/   4940	0017_dataset_ysq1_1440_768_obb
   8000/   8000	0018_syq4_dataset_768_768_obb_bus
   8000/   8000	0019_gm7_dataset_768_768_obb_bus
  11052/  11052	0020_web-collection-003_1184_768_768_obb
   1604/   1604	0022_UAV-ROD_dataset
    688/    688	0023_VSAI_dataset_2
   9708/   9708	0024_DroneVehicle_dataset
  10420/  10420	0025_VAID_dataset_aabb
   1923/   1923	0026_VEDAI_dataset
Training set:     80654
Test set:          4245
Batch Size:           4
Learning Rate: 0.000100
Num of Epoch:  80

[RESULT]: Train. Epoch: 63, summary_loss: 0.11789, time: 12.8 mins                          
[RESULT]: Val. Epoch: 63, summary_loss: 0.12051, time: 1.5 mins                         
2022-09-30T09:12:32.419383
LR: 2.5e-05
/home/me/1TSSD/efficientdet-pytorch/_models/z0008_only_5_new_dataset_including_VAID_aabb_patient2_80epochs_train0.95_seed167/best-checkpoint-063epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.46% | 99.43% | 99.43% | 99.43% | 99.39% | 99.17% | 98.68% | 96.29% | 80.13% | 15.26% | 88.67% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.67

[RESULT]: Train. Epoch: 79, summary_loss: 0.11399, time: 12.7 mins                          
[RESULT]: Val. Epoch: 79, summary_loss: 0.11647, time: 1.5 mins                         
/home/me/1TSSD/efficientdet-pytorch/_models/z0008_only_5_new_dataset_including_VAID_aabb_patient2_80epochs_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.48% | 99.48% | 99.48% | 99.48% | 99.34% | 99.15% | 98.46% | 95.59% | 75.40% | 13.39% | 87.93% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:87.93
88.03_0.17
	not converge yet @ 80th epoch
	lr reduced @ 37, 57, 74th epoch
	mAP & loss are more noisy than trainning without VAID_aabb
		so VAID_aabb introduces the difficulty in trainning...
----------------------------------------------------------------------------------
test new lr schedule with bs4, 2080ti and 5k samples for each virtual epoch

# train82 with 5 new datasets
# lr=0.0002, min_lr=lr/32, patient=1, max_epoch=80
# batch_size = 4, 80 virtual epochs with 5k samples
# multistep_lr_schedule = [15,30,40,50,60,70]
cp trainz0013.py train2.py
python train2.py z0013_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_5k_samples_per_virtual_epoch_train0.95_seed167 167

87.59_0.16
	still noisy yet
		need more trainning
----------------------------------------------------------------------------------
# train82 with 5 new datasets
# lr=0.0002, min_lr=lr/32, max_epoch=80
# batch_size = 4, 80 virtual epochs with 1w samples
# multistep_lr_schedule = [15,30,40,50,60,70]
cp trainz0015.py train2.py
python train2.py z0015_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_1w_samples_per_virtual_epoch_train0.95_seed167 167

z0013_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_5k_samples_per_virtual_epoch_train0.95_seed167 167
	vs z0015_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_1w_samples_per_virtual_epoch_train0.95_seed167 167
		87.59_0.16 vs 88.17_0.18
			train longer (5k per virtual epoch => 1w)
				helps in AABB mAPs and final loss(0.1343 => 0.1234)

88.17_0.18
	less noisy than z0013
		but there are still much room to improve...
			5 new dataset are too noisy?
			or try higher lr?
----------------------------------------------------------------------------------
without 5 new datasets, lr*=2
# train82 without new datasets
# lr=0.0004, min_lr=lr/32, max_epoch=80
# batch_size = 4, 80 virtual epochs with 1w samples
# multistep_lr_schedule = [15,30,40,50,60,70]
cp trainz0019.py train2.py
python train2.py z0019_without_new_datasets_lr15-30-40-50-60-70_bs4_lr4e-4_1w_samples_per_virtual_epoch_train0.95_seed167 167

/home/me/1TSSD/efficientdet_pytorch/_models/z0019_without_new_datasets_lr15-30-40-50-60-70_bs4_lr4e-4_2w_samples_per_virtual_epoch_train0.95_seed167/best-checkpoint-067epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.59% | 99.59% | 99.59% | 99.59% | 99.50% | 99.21% | 98.59% | 95.79% | 78.43% | 15.60% | 88.55% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.55

/home/me/1TSSD/efficientdet_pytorch/_models/z0019_without_new_datasets_lr15-30-40-50-60-70_bs4_lr4e-4_2w_samples_per_virtual_epoch_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.58% | 99.58% | 99.58% | 99.58% | 99.39% | 99.20% | 98.58% | 95.32% | 78.40% | 15.44% | 88.46% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.46
88.34_0.13
----------------------------------------------------------------------------------
# train82 without new datasets
# lr=0.0002, min_lr=lr/32, max_epoch=80
# batch_size = 4, 80 virtual epochs with 1w samples
# multistep_lr_schedule = [15,30,40,50,60,70]
cp trainz0018.py train2.py
python train2.py z0018_without_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_1w_samples_per_virtual_epoch_train0.95_seed167 167

LR: 5e-05
[RESULT]: Train. Epoch: 33, summary_loss: 0.10666, time: 12.9 mins                          
[RESULT]: Val. Epoch: 33, summary_loss: 0.10445, time: 1.1 mins                       
/home/me/1TSSD/efficientdet_pytorch/_models/z0018_without_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_2w_samples_per_virtual_epoch_train0.95_seed167/best-checkpoint-033epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.52% | 99.52% | 99.52% | 99.48% | 99.45% | 99.08% | 98.71% | 96.31% | 79.81% | 16.50% | 88.79% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.79

LR: 3.125e-06
[RESULT]: Train. Epoch: 79, summary_loss: 0.09444, time: 12.8 mins                          
[RESULT]: Val. Epoch: 79, summary_loss: 0.09269, time: 1.1 mins                       
/home/me/1TSSD/efficientdet_pytorch/_models/z0018_without_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_2w_samples_per_virtual_epoch_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.49% | 99.49% | 99.49% | 99.49% | 99.34% | 99.19% | 98.63% | 96.41% | 79.23% | 15.56% | 88.63% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.63
88.43_0.15
z0018_without_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_1w_samples_per_virtual_epoch_train0.95_seed167 167
	vs z0019_without_new_datasets_lr15-30-40-50-60-70_bs4_lr4e-4_1w_samples_per_virtual_epoch_train0.95_seed167
		88.43_0.15 vs 88.34_0.13
			higher lr(0.0004) doesn't helps on AABB mAPs or loss for old datasets@2021
----------------------------------------------------------------------------------
# train82 with 5 new datasets
# lr=0.0002, min_lr=lr/32, max_epoch=80
# batch_size = 4, 80 virtual epochs with 2w samples
# multistep_lr_schedule = [15,30,40,50,60,70]
cp trainz0017.py train2.py
python train2.py z0017_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_2w_samples_per_virtual_epoch_train0.95_seed167 167

LR: 3.125e-06
[RESULT]: Train. Epoch: 79, summary_loss: 0.10807, time: 25.4 mins                           
[RESULT]: Val. Epoch: 79, summary_loss: 0.11196, time: 1.5 mins                         
/home/me/1TSSD/efficientdet_pytorch/_models/z0017_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_2w_samples_per_virtual_epoch_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.49% | 99.49% | 99.49% | 99.49% | 99.44% | 99.15% | 98.70% | 96.48% | 78.25% | 13.54% | 88.35% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.35
88.52_0.15

still helpful to train even longer? 1w => 2w?
	yes, but only a little...
z0015_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_1w_samples_per_virtual_epoch_train0.95_seed167
	vs z0017_with_5_new_datasets_lr15-30-40-50-60-70_bs4_lr2e-4_2w_samples_per_virtual_epoch_train0.95_seed167 167
		88.17_0.18 vs 88.52_0.15
----------------------------------------------------------------------------------
# za0020, without new datasets
# lr=0.0001, min_lr=lr/32, max_epoch=80
# batch_size = 4, 80 virtual epochs with 1w samples
# multistep_lr_schedule = [30,40,50,60]
cp trainza0020.py train2.py
python train2.py za0020_without_new_datasets_lr30-40-50-60_bs4_lr1e-4_1w_samples_per_virtual_epoch_train0.95_seed167 167

LR: 6.25e-06
[RESULT]: Train. Epoch: 79, summary_loss: 0.08883, time: 12.8 mins                          
[RESULT]: Val. Epoch: 79, summary_loss: 0.08770, time: 1.1 mins                       
/home/me/1TSSD/efficientdet_pytorch/_models/za0020_without_new_datasets_lr30-40-50-60_bs4_lr1e-4_1w_samples_per_virtual_epoch_train0.95_seed167/best-checkpoint-079epoch.bin
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:|   50%  |   55%  |   60%  |   65%  |   70%  |   75%  |   80%  |   85%  |   90%  |   95%  | 50-95% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
DETAIL:| 99.36% | 99.36% | 99.32% | 99.32% | 99.16% | 99.06% | 98.35% | 95.99% | 77.21% | 14.37% | 88.15% |
DETAIL:+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+
SUMMARY:88.15
88.08_0.15

----------------------------------------------------------------------------------
# za0021, without new datasets
# lr=0.0002, min_lr=lr/32, max_epoch=80
# batch_size = 4, 80 virtual epochs with 1w samples
# multistep_lr_schedule = [15,30,40,50,60,70]
cp trainza0021.py train2.py
python train2.py za0021_without_new_datasets_lr15-30-40-50-60-70_bs4_lr1e-4_1w_samples_per_virtual_epoch_train0.95_seed167 167



